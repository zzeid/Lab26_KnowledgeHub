{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "# PROJEKTS: Knowledge Hub\n",
                                        "\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "Situācija\n",
                                        "Tu esi tikko pieņemts darbā par MI Inženieri. Uzņēmuma vadītājs tev iedevis mapi UNSORTED_DATA, kurā ir haoss - sapulču ieraksti, tāfeles fotogrāfijas un līgumu melnraksti.\n",
                                        "\n",
                                        "Nevienam nav laika to visu lasīt vai klausīties.\n",
                                        "\n",
                                        "## Tavs Uzdevums:\n",
                                        "\n",
                                        "Uzbūvēt Multimodālu RAG Sistēmu, kas \"apēd\" šos failus un ļauj direktoram čatā uzdot jautājumus (piemēram: \"Cik mēs esam parādā?\" vai \"Ko nolēma par mārketingu?\"), saņemot precīzas atbildes ar atsaucēm."
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Vides sagatavošana"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 1,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Mounted at /content/drive\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "from google.colab import drive\n",
                                        "drive.mount('/content/drive')"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 2,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
                                                            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
                                                            "Collecting langchain-community\n",
                                                            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
                                                            "Collecting langchain-openai\n",
                                                            "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
                                                            "Collecting chromadb\n",
                                                            "  Downloading chromadb-1.5.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
                                                            "Collecting pypdf\n",
                                                            "  Downloading pypdf-6.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
                                                            "Collecting pymupdf\n",
                                                            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
                                                            "Collecting openai-whisper\n",
                                                            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
                                                            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                                                            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
                                                            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
                                                            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
                                                            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
                                                            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
                                                            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
                                                            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
                                                            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
                                                            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
                                                            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
                                                            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
                                                            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
                                                            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.9)\n",
                                                            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
                                                            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
                                                            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
                                                            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
                                                            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
                                                            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
                                                            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
                                                            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
                                                            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.3)\n",
                                                            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
                                                            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
                                                            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
                                                            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.9)\n",
                                                            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
                                                            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
                                                            "Collecting langchain-core<2.0.0,>=1.2.8 (from langchain)\n",
                                                            "  Downloading langchain_core-1.2.11-py3-none-any.whl.metadata (4.4 kB)\n",
                                                            "Collecting build>=1.0.3 (from chromadb)\n",
                                                            "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
                                                            "Collecting pybase64>=1.4.1 (from chromadb)\n",
                                                            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
                                                            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
                                                            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
                                                            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
                                                            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
                                                            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
                                                            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
                                                            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
                                                            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
                                                            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
                                                            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.2)\n",
                                                            "Collecting pypika>=0.48.9 (from chromadb)\n",
                                                            "  Downloading pypika-0.51.1-py2.py3-none-any.whl.metadata (51 kB)\n",
                                                            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
                                                            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
                                                            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
                                                            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
                                                            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
                                                            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.1)\n",
                                                            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
                                                            "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
                                                            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
                                                            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.7)\n",
                                                            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
                                                            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.26.0)\n",
                                                            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
                                                            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
                                                            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cpu)\n",
                                                            "Collecting triton>=2 (from openai-whisper)\n",
                                                            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
                                                            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
                                                            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
                                                            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
                                                            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
                                                            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
                                                            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
                                                            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
                                                            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
                                                            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
                                                            "Requirement already satisfied: packaging>=24.0 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (26.0)\n",
                                                            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
                                                            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
                                                            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
                                                            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
                                                            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
                                                            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
                                                            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
                                                            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
                                                            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
                                                            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
                                                            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
                                                            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
                                                            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
                                                            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
                                                            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
                                                            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
                                                            "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
                                                            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
                                                            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
                                                            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
                                                            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
                                                            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
                                                            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
                                                            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
                                                            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
                                                            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
                                                            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
                                                            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
                                                            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
                                                            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
                                                            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.6)\n",
                                                            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
                                                            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
                                                            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
                                                            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
                                                            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
                                                            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
                                                            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
                                                            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
                                                            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
                                                            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
                                                            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
                                                            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
                                                            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
                                                            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
                                                            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
                                                            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
                                                            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
                                                            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
                                                            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
                                                            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
                                                            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
                                                            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
                                                            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
                                                            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (1.4.0)\n",
                                                            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
                                                            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
                                                            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
                                                            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
                                                            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
                                                            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
                                                            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
                                                            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.3)\n",
                                                            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
                                                            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
                                                            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
                                                            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
                                                            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
                                                            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.21.1)\n",
                                                            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
                                                            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
                                                            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
                                                            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
                                                            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
                                                            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
                                                            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
                                                            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
                                                            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
                                                            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
                                                            "\u001b[?25hDownloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading chromadb-1.5.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
                                                            "\u001b[?25hDownloading pypdf-6.7.0-py3-none-any.whl (330 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.6/330.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
                                                            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading build-1.4.0-py3-none-any.whl (24 kB)\n",
                                                            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
                                                            "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading langchain_core-1.2.11-py3-none-any.whl (500 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.1/500.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
                                                            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
                                                            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
                                                            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading pypika-0.51.1-py2.py3-none-any.whl (60 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
                                                            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
                                                            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
                                                            "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
                                                            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
                                                            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                                                            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
                                                            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
                                                            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
                                                            "Building wheels for collected packages: openai-whisper\n",
                                                            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
                                                            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803980 sha256=ff4718e3ea6b9c6f8918cf24f9ff89d026c786bb2011e834f6c39eca9935c8c3\n",
                                                            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
                                                            "Successfully built openai-whisper\n",
                                                            "Installing collected packages: pypika, durationpy, triton, requests, pyproject_hooks, pypdf, pymupdf, pybase64, opentelemetry-proto, mypy-extensions, marshmallow, bcrypt, backoff, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, build, opentelemetry-semantic-conventions, openai-whisper, kubernetes, dataclasses-json, opentelemetry-sdk, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain-classic, chromadb, langchain-community\n",
                                                            "  Attempting uninstall: requests\n",
                                                            "    Found existing installation: requests 2.32.4\n",
                                                            "    Uninstalling requests-2.32.4:\n",
                                                            "      Successfully uninstalled requests-2.32.4\n",
                                                            "  Attempting uninstall: opentelemetry-proto\n",
                                                            "    Found existing installation: opentelemetry-proto 1.38.0\n",
                                                            "    Uninstalling opentelemetry-proto-1.38.0:\n",
                                                            "      Successfully uninstalled opentelemetry-proto-1.38.0\n",
                                                            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
                                                            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0\n",
                                                            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:\n",
                                                            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.0\n",
                                                            "  Attempting uninstall: opentelemetry-api\n",
                                                            "    Found existing installation: opentelemetry-api 1.38.0\n",
                                                            "    Uninstalling opentelemetry-api-1.38.0:\n",
                                                            "      Successfully uninstalled opentelemetry-api-1.38.0\n",
                                                            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
                                                            "    Found existing installation: opentelemetry-semantic-conventions 0.59b0\n",
                                                            "    Uninstalling opentelemetry-semantic-conventions-0.59b0:\n",
                                                            "      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0\n",
                                                            "  Attempting uninstall: opentelemetry-sdk\n",
                                                            "    Found existing installation: opentelemetry-sdk 1.38.0\n",
                                                            "    Uninstalling opentelemetry-sdk-1.38.0:\n",
                                                            "      Successfully uninstalled opentelemetry-sdk-1.38.0\n",
                                                            "  Attempting uninstall: langchain-core\n",
                                                            "    Found existing installation: langchain-core 1.2.9\n",
                                                            "    Uninstalling langchain-core-1.2.9:\n",
                                                            "      Successfully uninstalled langchain-core-1.2.9\n",
                                                            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                                                            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
                                                            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
                                                            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
                                                            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
                                                            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
                                                            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.5.0 dataclasses-json-0.6.7 durationpy-0.10 kubernetes-35.0.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.11 langchain-openai-1.1.9 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 onnxruntime-1.24.1 openai-whisper-20250625 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pymupdf-1.26.7 pypdf-6.7.0 pypika-0.51.1 pyproject_hooks-1.2.0 requests-2.32.5 triton-3.6.0 typing-inspect-0.9.0\n",
                                                            "Reading package lists... Done\n",
                                                            "Building dependency tree... Done\n",
                                                            "Reading state information... Done\n",
                                                            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
                                                            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# Instalējam nepieciešamās bibliotēkas\n",
                                        "%pip install openai langchain langchain-community langchain-openai chromadb pypdf pymupdf openai-whisper tiktoken\n",
                                        "!apt-get install ffmpeg -y  # Nepieciešams priekš Whisper audio apstrādes\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 3,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "✅ Visi faili atrasti mapē: /content/drive/MyDrive/Colab Notebooks/BDA_M1/Lab26_KnowledgeHub\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "import os\n",
                                        "import getpass\n",
                                        "from pathlib import Path\n",
                                        "from google.colab import drive\n",
                                        "\n",
                                        "# 1. Pievienojam Google Drive (ja vēl nav pievienots)\n",
                                        "if not os.path.exists('/content/drive'):\n",
                                        "    drive.mount('/content/drive')\n",
                                        "\n",
                                        "# 2. Definējam darba mapi (ceļš no tava ekrānšāviņa)\n",
                                        "BASE_PATH = Path(\"/content/drive/MyDrive/Colab Notebooks/BDA_M1/Lab26_KnowledgeHub\")\n",
                                        "\n",
                                        "# 3. Ievadi OpenAI API atslēgu\n",
                                        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Ievadi OpenAI API Key: \")\n",
                                        "\n",
                                        "# 4. Pārbaudām failus\n",
                                        "required_files = [\"project.pdf\", \"meeting.mp3\", \"whiteboard.png\"] # Pamanīju, ka tev ir .png\n",
                                        "missing_files = [f for f in required_files if not (BASE_PATH / f).exists()]\n",
                                        "\n",
                                        "if missing_files:\n",
                                        "    print(f\"❌ TRŪKST FAILU mapē {BASE_PATH}: {missing_files}\")\n",
                                        "    print(\"Pārbaudi failu nosaukumus!\")\n",
                                        "else:\n",
                                        "    print(f\"✅ Visi faili atrasti mapē: {BASE_PATH}\")\n",
                                        "    # Iestatām pilnos ceļus ērtākai lietošanai\n",
                                        "    pdf_path = str(BASE_PATH / \"project.pdf\")\n",
                                        "    audio_path = str(BASE_PATH / \"meeting.mp3\")\n",
                                        "    image_path = str(BASE_PATH / \"whiteboard.png\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Izstrādes soļi (Ingestion & Vector Store)\n",
                                        "Šis kods \"apēd\" failus no Google Drive mapes.\n",
                                        "* Whisper lasa audio no Drive ceļa.\n",
                                        "* GPT-4o lasa attēlu no Drive ceļa.\n",
                                        "* PyPDFLoader lasa PDF no Drive ceļa."
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 4,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "🔎 Sāku datu apstrādi... (Tas var aizņemt pāris minūtes)\n",
                                                            "   🎤 Apstrādāju audio: meeting.mp3...\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stderr",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 335MiB/s]\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "   🖼️ Apstrādāju attēlu: whiteboard.png...\n",
                                                            "   📄 Apstrādāju PDF: project.pdf...\n",
                                                            "   PDF loaded with PyMuPDFLoader; pages kept: 13\n",
                                                            "   💾 Veidoju Vektoru Datubāzi (ChromaDB)...\n",
                                                            "✅ Datu bāze gatava! Apstrādāti 40 informācijas gabali.\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "import whisper\n",
                                        "from langchain_community.document_loaders import PyPDFLoader\n",
                                        "try:\n",
                                        "    from langchain_community.document_loaders import PyMuPDFLoader\n",
                                        "except Exception:\n",
                                        "    PyMuPDFLoader = None\n",
                                        "try:\n",
                                        "    import fitz  # PyMuPDF, used for PDF page -> image OCR fallback\n",
                                        "except Exception:\n",
                                        "    fitz = None\n",
                                        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                                        "from langchain_openai import OpenAIEmbeddings\n",
                                        "from langchain_community.vectorstores import Chroma\n",
                                        "from langchain_core.documents import Document\n",
                                        "from openai import OpenAI\n",
                                        "import base64\n",
                                        "import logging\n",
                                        "import re\n",
                                        "\n",
                                        "# Iniciējam OpenAI klientu attēlu apstrādei\n",
                                        "client = OpenAI()\n",
                                        "\n",
                                        "print(\"🔎 Sāku datu apstrādi... (Tas var aizņemt pāris minūtes)\")\n",
                                        "all_documents = []\n",
                                        "\n",
                                        "# --- A. DATU \"APĒŠANA\" (Ingestion) ---\n",
                                        "\n",
                                        "# 1. AUDIO APSTRĀDE (Whisper)\n",
                                        "print(f\"   🎤 Apstrādāju audio: {os.path.basename(audio_path)}...\")\n",
                                        "whisper_model = whisper.load_model(\"base\")\n",
                                        "# Whisper ņem faila ceļu tieši no Drive\n",
                                        "result = whisper_model.transcribe(\n",
                                        "    audio_path,\n",
                                        "    task=\"transcribe\",\n",
                                        "    language=\"en\",\n",
                                        "    fp16=False,\n",
                                        "    condition_on_previous_text=True,\n",
                                        ")\n",
                                        "segments = result.get(\"segments\", [])\n",
                                        "audio_text = \"\\n\".join([f\"[{s['start']:.1f}-{s['end']:.1f}] {s['text'].strip()}\" for s in segments]) if segments else result.get(\"text\", \"\")\n",
                                        "all_documents.append(Document(page_content=audio_text, metadata={\"source\": \"meeting.mp3\"}))\n",
                                        "\n",
                                        "\n",
                                        "# 2. ATTĒLA APSTRĀDE (GPT-4o Vision)\n",
                                        "print(f\"   🖼️ Apstrādāju attēlu: {os.path.basename(image_path)}...\")\n",
                                        "\n",
                                        "def encode_image(image_path):\n",
                                        "    with open(image_path, \"rb\") as image_file:\n",
                                        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
                                        "\n",
                                        "# Kodējam attēlu no Drive\n",
                                        "base64_image = encode_image(image_path)\n",
                                        "\n",
                                        "response = client.chat.completions.create(\n",
                                        "    model=\"gpt-4o\",\n",
                                        "    temperature=0,\n",
                                        "    messages=[\n",
                                        "        {\n",
                                        "            \"role\": \"user\",\n",
                                        "            \"content\": [\n",
                                        "                {\n",
                                        "                    \"type\": \"text\",\n",
                                        "                    \"text\": \"Extract all visible text exactly from this image. If there is a table, transcribe each row. Keep every number exactly as written (including commas, currency symbols, and dates). Then provide a short section named NUMBERS_FOUND that lists all numbers you see.\",\n",
                                        "                },\n",
                                        "                {\n",
                                        "                    \"type\": \"image_url\",\n",
                                        "                    \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\", \"detail\": \"high\"},\n",
                                        "                },\n",
                                        "            ],\n",
                                        "        }\n",
                                        "    ],\n",
                                        "    max_tokens=1600,\n",
                                        ")\n",
                                        "image_description = response.choices[0].message.content\n",
                                        "# Add retrieval keywords so numeric queries match this chunk more reliably.\n",
                                        "image_text_for_index = (\n",
                                        "    \"Keywords: numbers, digits, amounts, budget, costs, estimated cost, actual, total budget, current spend.\\n\\n\"\n",
                                        "    f\"{image_description}\"\n",
                                        ")\n",
                                        "all_documents.append(Document(page_content=image_text_for_index, metadata={\"source\": \"whiteboard.png\"}))\n",
                                        "\n",
                                        "\n",
                                        "def ocr_pdf_page_with_vision(pdf_file_path, page_index):\n",
                                        "    if fitz is None:\n",
                                        "        return \"\"\n",
                                        "\n",
                                        "    try:\n",
                                        "        with fitz.open(pdf_file_path) as pdf_doc:\n",
                                        "            if page_index < 0 or page_index >= len(pdf_doc):\n",
                                        "                return \"\"\n",
                                        "            page = pdf_doc.load_page(page_index)\n",
                                        "            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2), alpha=False)\n",
                                        "            page_b64 = base64.b64encode(pix.tobytes(\"png\")).decode(\"utf-8\")\n",
                                        "    except Exception as e:\n",
                                        "        print(f\"   [PDF OCR render fallback] lapa {page_index + 1}: {e}\")\n",
                                        "        return \"\"\n",
                                        "\n",
                                        "    try:\n",
                                        "        ocr_response = client.chat.completions.create(\n",
                                        "            model=\"gpt-4o\",\n",
                                        "            temperature=0,\n",
                                        "            messages=[\n",
                                        "                {\n",
                                        "                    \"role\": \"user\",\n",
                                        "                    \"content\": [\n",
                                        "                        {\n",
                                        "                            \"type\": \"text\",\n",
                                        "                            \"text\": \"Extract all visible text exactly from this PDF page image. Return only the transcribed text. If no readable text is present, return an empty string.\",\n",
                                        "                        },\n",
                                        "                        {\n",
                                        "                            \"type\": \"image_url\",\n",
                                        "                            \"image_url\": {\"url\": f\"data:image/png;base64,{page_b64}\", \"detail\": \"high\"},\n",
                                        "                        },\n",
                                        "                    ],\n",
                                        "                }\n",
                                        "            ],\n",
                                        "            max_tokens=1600,\n",
                                        "        )\n",
                                        "        return (ocr_response.choices[0].message.content or \"\").strip()\n",
                                        "    except Exception as e:\n",
                                        "        print(f\"   [PDF OCR API fallback] lapa {page_index + 1}: {e}\")\n",
                                        "        return \"\"\n",
                                        "\n",
                                        "\n",
                                        "# 3. PDF APSTRĀDE\n",
                                        "print(f\"   📄 Apstrādāju PDF: {os.path.basename(pdf_path)}...\")\n",
                                        "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
                                        "pdf_docs = []\n",
                                        "pdf_loader_used = \"PyPDFLoader\"\n",
                                        "try:\n",
                                        "    if PyMuPDFLoader is not None:\n",
                                        "        pdf_docs = PyMuPDFLoader(pdf_path).load()\n",
                                        "        pdf_loader_used = \"PyMuPDFLoader\"\n",
                                        "    else:\n",
                                        "        raise ImportError(\"PyMuPDFLoader not available\")\n",
                                        "except Exception as e:\n",
                                        "    print(f\"   [PDF fallback] {e}\")\n",
                                        "    pdf_docs = PyPDFLoader(pdf_path).load()\n",
                                        "\n",
                                        "clean_pdf_docs = []\n",
                                        "for idx, d in enumerate(pdf_docs):\n",
                                        "    text = (d.page_content or \"\").strip()\n",
                                        "    if not text:\n",
                                        "        page_idx = d.metadata.get(\"page\", idx)\n",
                                        "        if not isinstance(page_idx, int):\n",
                                        "            try:\n",
                                        "                page_idx = int(page_idx)\n",
                                        "            except Exception:\n",
                                        "                page_idx = idx\n",
                                        "\n",
                                        "        ocr_text = ocr_pdf_page_with_vision(pdf_path, page_idx)\n",
                                        "        if not ocr_text:\n",
                                        "            continue\n",
                                        "\n",
                                        "        text = ocr_text\n",
                                        "        d.metadata = {**d.metadata, \"ocr\": True}\n",
                                        "    d.page_content = \"\\n\".join([line.strip() for line in text.splitlines() if line.strip()])\n",
                                        "    d.metadata = {**d.metadata, \"source\": \"project.pdf\"}\n",
                                        "    clean_pdf_docs.append(d)\n",
                                        "\n",
                                        "pdf_docs = clean_pdf_docs\n",
                                        "print(f\"   PDF loaded with {pdf_loader_used}; pages kept: {len(pdf_docs)}\")\n",
                                        "# Pievienojam PDF lapas kopējam sarakstam\n",
                                        "all_documents.extend(pdf_docs)\n",
                                        "\n",
                                        "\n",
                                        "# --- B. ZINĀŠANU BĀZE (Vector Store) ---\n",
                                        "\n",
                                        "print(\"   💾 Veidoju Vektoru Datubāzi (ChromaDB)...\")\n",
                                        "\n",
                                        "# Sadalām tekstu gabalos\n",
                                        "text_splitter = RecursiveCharacterTextSplitter(\n",
                                        "    chunk_size=1000,\n",
                                        "    chunk_overlap=200\n",
                                        ")\n",
                                        "splits = text_splitter.split_documents(all_documents)\n",
                                        "\n",
                                        "def _sec_label(value):\n",
                                        "    return str(value).replace(\".\", \":\")\n",
                                        "\n",
                                        "def extract_first_audio_timestamp(text):\n",
                                        "    match = re.search(r\"\\[(\\d+(?:\\.\\d+)?)\\s*-\\s*(\\d+(?:\\.\\d+)?)\\]\", text or \"\")\n",
                                        "    if not match:\n",
                                        "        return None\n",
                                        "    start_sec = _sec_label(match.group(1))\n",
                                        "    end_sec = _sec_label(match.group(2))\n",
                                        "    return f\"{start_sec}-{end_sec} sekundes\"\n",
                                        "\n",
                                        "for d in splits:\n",
                                        "    if d.metadata.get(\"source\") == \"meeting.mp3\":\n",
                                        "        timestamp = extract_first_audio_timestamp(d.page_content)\n",
                                        "        if timestamp:\n",
                                        "            d.metadata[\"timestamp\"] = timestamp\n",
                                        "\n",
                                        "# Saglabājam ChromaDB (operatīvajā atmiņā)\n",
                                        "vectorstore = Chroma.from_documents(\n",
                                        "    documents=splits,\n",
                                        "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
                                        ")\n",
                                        "\n",
                                        "print(f\"✅ Datu bāze gatava! Apstrādāti {len(splits)} informācijas gabali.\")"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Kods čata interfeisam (RAG funkcija)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 18,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Projekta Smadzenes ir gatavas. Jautā man jebko par failiem!\n",
                                                            "Notebook režīms: lieto ask_question(\"tavs jautājums\") nākamajā šūnā.\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "from langchain_openai import ChatOpenAI\n",
                                        "from langchain_core.prompts import ChatPromptTemplate\n",
                                        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
                                        "from langchain_core.output_parsers import StrOutputParser\n",
                                        "import re\n",
                                        "\n",
                                        "\n",
                                        "# --- RAG SISTĒMAS UZBŪVE ---\n",
                                        "\n",
                                        "# 1. Definējam LLM\n",
                                        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
                                        "\n",
                                        "# 2. Definējam meklētāju\n",
                                        "retriever = vectorstore.as_retriever(\n",
                                        "    search_type=\"mmr\",\n",
                                        "    search_kwargs={\"k\": 10, \"fetch_k\": 40, \"lambda_mult\": 0.15}\n",
                                        ")\n",
                                        "\n",
                                        "\n",
                                        "def list_sources():\n",
                                        "    return sorted({d.metadata.get(\"source\", \"Nezināms\") for d in splits if d.metadata.get(\"source\")})\n",
                                        "\n",
                                        "\n",
                                        "def dedupe_docs(docs):\n",
                                        "    seen = set()\n",
                                        "    unique_docs = []\n",
                                        "    for d in docs:\n",
                                        "        source = d.metadata.get(\"source\", \"Nezināms\")\n",
                                        "        page = d.metadata.get(\"page\", None)\n",
                                        "        key = (source, page, (d.page_content or \"\").strip()[:240])\n",
                                        "        if key in seen:\n",
                                        "            continue\n",
                                        "        seen.add(key)\n",
                                        "        unique_docs.append(d)\n",
                                        "    return unique_docs\n",
                                        "\n",
                                        "\n",
                                        "def format_used_sources(docs):\n",
                                        "    sources = sorted({\n",
                                        "        d.metadata.get(\"source\", \"Nezināms\")\n",
                                        "        for d in docs\n",
                                        "        if d.metadata.get(\"source\")\n",
                                        "    })\n",
                                        "    return \", \".join(sources) if sources else \"Neviens\"\n",
                                        "\n",
                                        "\n",
                                        "def enrich_audio_citations(answer, docs):\n",
                                        "    def normalize_meeting_range(text):\n",
                                        "        pattern = re.compile(\n",
                                        "            r\"(?i)(Avots:\\s*meeting\\.mp3,\\s*)(\\d+(?:[\\.:]\\d+)?)\\s*-\\s*(\\d+(?:[\\.:]\\d+)?)(?:\\s*sekundes)?\"\n",
                                        "        )\n",
                                        "        return pattern.sub(\n",
                                        "            lambda m: f\"{m.group(1)}{m.group(2).replace('.', ':')}-{m.group(3).replace('.', ':')} sekundes\",\n",
                                        "            text,\n",
                                        "        )\n",
                                        "\n",
                                        "    answer = normalize_meeting_range(answer)\n",
                                        "\n",
                                        "    timestamps = []\n",
                                        "    for d in docs:\n",
                                        "        if d.metadata.get(\"source\") != \"meeting.mp3\":\n",
                                        "            continue\n",
                                        "        timestamp = d.metadata.get(\"timestamp\")\n",
                                        "        if timestamp and timestamp not in timestamps:\n",
                                        "            timestamps.append(timestamp)\n",
                                        "    if not timestamps:\n",
                                        "        return answer\n",
                                        "\n",
                                        "    default_timestamp = timestamps[0]\n",
                                        "    answer = re.sub(\n",
                                        "        r\"\\[Avots:\\s*meeting\\.mp3\\s*\\]\",\n",
                                        "        f\"[Avots: meeting.mp3, {default_timestamp}]\",\n",
                                        "        answer,\n",
                                        "        flags=re.IGNORECASE,\n",
                                        "    )\n",
                                        "    answer = re.sub(\n",
                                        "        r\"\\(Avots:\\s*meeting\\.mp3\\s*\\)\",\n",
                                        "        f\"(Avots: meeting.mp3, {default_timestamp})\",\n",
                                        "        answer,\n",
                                        "        flags=re.IGNORECASE,\n",
                                        "    )\n",
                                        "    return normalize_meeting_range(answer)\n",
                                        "\n",
                                        "\n",
                                        "def retrieve_docs(question, per_source_k=3, global_k=4):\n",
                                        "    combined_docs = []\n",
                                        "    source_hits = {}\n",
                                        "\n",
                                        "    # 1) Meklējam katra avota atsevišķi\n",
                                        "    for source in list_sources():\n",
                                        "        docs = []\n",
                                        "        try:\n",
                                        "            docs = vectorstore.similarity_search(\n",
                                        "                question,\n",
                                        "                k=per_source_k,\n",
                                        "                filter={\"source\": source},\n",
                                        "            )\n",
                                        "        except Exception:\n",
                                        "            docs = []\n",
                                        "\n",
                                        "        if not docs:\n",
                                        "            docs = [\n",
                                        "                d for d in retriever.invoke(question)\n",
                                        "                if d.metadata.get(\"source\") == source\n",
                                        "            ][:per_source_k]\n",
                                        "\n",
                                        "        source_hits[source] = docs\n",
                                        "        combined_docs.extend(docs)\n",
                                        "\n",
                                        "    # 2) Pievienojam papildu globāli relevantos gabalus\n",
                                        "    combined_docs.extend(retriever.invoke(question)[:global_k])\n",
                                        "\n",
                                        "    return dedupe_docs(combined_docs), source_hits\n",
                                        "\n",
                                        "\n",
                                        "def format_docs(docs):\n",
                                        "    grouped = {}\n",
                                        "    for d in docs:\n",
                                        "        source = d.metadata.get(\"source\", \"Nezināms\")\n",
                                        "        grouped.setdefault(source, []).append(d)\n",
                                        "\n",
                                        "    blocks = []\n",
                                        "    for source in sorted(grouped.keys()):\n",
                                        "        blocks.append(f\"=== Avots: {source} ===\")\n",
                                        "        for i, d in enumerate(grouped[source], start=1):\n",
                                        "            page = d.metadata.get(\"page\")\n",
                                        "            timestamp = d.metadata.get(\"timestamp\")\n",
                                        "            if source == \"meeting.mp3\" and timestamp:\n",
                                        "                locator = f\", laiks {timestamp}\"\n",
                                        "            else:\n",
                                        "                locator = f\", lapa {page + 1}\" if isinstance(page, int) else \"\"\n",
                                        "            blocks.append(f\"[{source}#{i}{locator}] {d.page_content}\")\n",
                                        "        blocks.append(\"\")\n",
                                        "\n",
                                        "    return \"\\n\".join(blocks).strip()\n",
                                        "\n",
                                        "\n",
                                        "def is_followup_question(question):\n",
                                        "    q = (question or \"\").strip().lower()\n",
                                        "    if not q:\n",
                                        "        return False\n",
                                        "\n",
                                        "    followup_patterns = [\n",
                                        "        r\"^un\\b\",\n",
                                        "        r\"^vēl\\b\",\n",
                                        "        r\"\\biepriekš\\w*\\b\",\n",
                                        "        r\"\\btas\\b\",\n",
                                        "        r\"\\btā\\b\",\n",
                                        "        r\"\\bšo\\b\",\n",
                                        "        r\"\\bkā ar\\b\",\n",
                                        "        r\"\\bcik tas\\b\",\n",
                                        "        r\"\\bun cik\\b\",\n",
                                        "        r\"\\bwhat about\\b\",\n",
                                        "        r\"\\band what\\b\",\n",
                                        "        r\"\\bit\\b\",\n",
                                        "        r\"\\bthat\\b\",\n",
                                        "    ]\n",
                                        "    return any(re.search(pattern, q) for pattern in followup_patterns)\n",
                                        "\n",
                                        "\n",
                                        "def format_chat_history(chat_history, max_turns=1):\n",
                                        "    if not chat_history:\n",
                                        "        return \"Nav iepriekšējas čata vēstures.\"\n",
                                        "    recent_turns = chat_history[-max_turns:]\n",
                                        "    lines = []\n",
                                        "    for idx, turn in enumerate(recent_turns, start=1):\n",
                                        "        q = (turn.get(\"question\") or \"\").strip()\n",
                                        "        a = (turn.get(\"answer\") or \"\").strip()\n",
                                        "        if q:\n",
                                        "            lines.append(f\"{idx}. Lietotājs: {q}\")\n",
                                        "        if a:\n",
                                        "            short_answer = re.sub(r\"\\s+\", \" \", a)[:260]\n",
                                        "            lines.append(f\"   Asistents: {short_answer}\")\n",
                                        "    return \"\\n\".join(lines) if lines else \"Nav iepriekšējas čata vēstures.\"\n",
                                        "\n",
                                        "\n",
                                        "def build_retrieval_query(question, chat_history):\n",
                                        "    if not chat_history or not is_followup_question(question):\n",
                                        "        return question\n",
                                        "\n",
                                        "    last_turn = chat_history[-1]\n",
                                        "    prev_question = (last_turn.get(\"question\") or \"\").strip()\n",
                                        "    prev_answer = (last_turn.get(\"answer\") or \"\").strip()\n",
                                        "\n",
                                        "    if not prev_question and not prev_answer:\n",
                                        "        return question\n",
                                        "\n",
                                        "    parts = []\n",
                                        "    parts.append(\"Šis ir turpinājuma jautājums. Interpretē atsauces uz iepriekšējo soli.\")\n",
                                        "    if prev_question:\n",
                                        "        parts.append(f\"Iepriekšējais jautājums: {prev_question}\")\n",
                                        "    if prev_answer:\n",
                                        "        parts.append(f\"Iepriekšējā atbilde: {prev_answer[:260]}\")\n",
                                        "    parts.append(f\"Pašreizējais jautājums: {question}\")\n",
                                        "    return \"\\n\".join(parts)\n",
                                        "\n",
                                        "\n",
                                        "def build_context(question):\n",
                                        "    use_history = bool(chat_history) and is_followup_question(question)\n",
                                        "    retrieval_query = build_retrieval_query(question, chat_history)\n",
                                        "    docs, source_hits = retrieve_docs(retrieval_query)\n",
                                        "    if not docs:\n",
                                        "        return \"NAV ATRASTS NEVIENS RELEVANTS FRAGMENTS.\"\n",
                                        "\n",
                                        "    missing = [source for source, hits in source_hits.items() if not hits]\n",
                                        "    header = \"\"\n",
                                        "    if missing:\n",
                                        "        header = (\n",
                                        "            \"PIEZĪME: šiem avotiem semantiskā meklēšana neatgrieza fragmentus: \"\n",
                                        "            + \", \".join(missing)\n",
                                        "            + \"\\n\\n\"\n",
                                        "        )\n",
                                        "\n",
                                        "    history_block = \"\"\n",
                                        "    if use_history:\n",
                                        "        history_block = (\n",
                                        "            \"=== Čata vēsture (iepriekšējais solis) ===\\n\"\n",
                                        "            + format_chat_history(chat_history)\n",
                                        "            + \"\\n\\n\"\n",
                                        "        )\n",
                                        "    return header + history_block + format_docs(docs)\n",
                                        "\n",
                                        "\n",
                                        "# 3. Definējam promptu\n",
                                        "template = \"\"\"Tu esi uzņēmuma stratēģiskais AI asistents.\n",
                                        "Tavs uzdevums ir atbildēt uz jautājumiem, izmantojot TIKAI zemāk sniegto kontekstu.\n",
                                        "\n",
                                        "Noteikumi:\n",
                                        "1) Izveido vienu apkopotu atbildi no visiem avotiem, kuros ir atbilstoša informācija.\n",
                                        "2) Ja viens fakts redzams vairākos avotos, apvieno to viena teikumā un pievieno visus avotus.\n",
                                        "3) Ja avoti savstarpēji pretrunojas, to arī norādi.\n",
                                        "4) Pēc katra būtiska fakta norādi avotu iekavās. MP3 avotam VIENMĒR pievieno sekunžu intervālu ar '.' un vienību 'sekundes' (piem., [Avots: meeting.mp3, 292.7-305.4 sekundes], [Avots: project.pdf]).\n",
                                        "5) Ja atbildes nav kontekstā, saki: \"Diemžēl failos šādas informācijas nav.\"\n",
                                        "6) Ja jautājums ir turpinājums iepriekšējam (piem., \"Un cik tas ir dolāros?\"), interpretē to pēc čata vēstures.\n",
                                        "7) Atbildi TIKAI uz pašreizējo jautājumu. Ja jautājums ir jauns un nav turpinājums, ignorē čata vēsturi.\n",
                                        "\n",
                                        "Konteksts:\n",
                                        "{context}\n",
                                        "\n",
                                        "Jautājums: {question}\n",
                                        "\"\"\"\n",
                                        "prompt = ChatPromptTemplate.from_template(template)\n",
                                        "\n",
                                        "# 4. RAG ķēde\n",
                                        "rag_chain = (\n",
                                        "    {\"context\": RunnableLambda(build_context), \"question\": RunnablePassthrough()}\n",
                                        "    | prompt\n",
                                        "    | llm\n",
                                        "    | StrOutputParser()\n",
                                        ")\n",
                                        "\n",
                                        "\n",
                                        "# --- NOTEBOOK ČATS (bez input cilpas) ---\n",
                                        "\n",
                                        "print(\"Projekta Smadzenes ir gatavas. Jautā man jebko par failiem!\")\n",
                                        "print(\"Notebook režīms: lieto ask_question(\\\"tavs jautājums\\\") nākamajā šūnā.\")\n",
                                        "\n",
                                        "chat_history = []\n",
                                        "\n",
                                        "\n",
                                        "def ask_question(user_question):\n",
                                        "    user_question = (user_question or \"\").strip()\n",
                                        "    if not user_question:\n",
                                        "        print(\"Kļūda: tukšs jautājums.\")\n",
                                        "        return None\n",
                                        "\n",
                                        "    if user_question.lower() in [\"exit\", \"quit\", \"beigt\", \"-\"]:\n",
                                        "        print(\"Čats pabeigts.\")\n",
                                        "        return None\n",
                                        "\n",
                                        "    try:\n",
                                        "        print(f\"   Saņemts jautājums: {user_question}\")\n",
                                        "        print(\"   Analizēju datus...\", flush=True)\n",
                                        "\n",
                                        "        response = rag_chain.invoke(user_question)\n",
                                        "\n",
                                        "        retrieval_query = build_retrieval_query(user_question, chat_history)\n",
                                        "        retrieved_docs, _ = retrieve_docs(retrieval_query)\n",
                                        "        response = enrich_audio_citations(response, retrieved_docs)\n",
                                        "        used_sources = format_used_sources(retrieved_docs)\n",
                                        "\n",
                                        "        print(f\"\\nJautājums:\\n{user_question}\")\n",
                                        "        print(f\"\\nAtbilde:\\n{response}\")\n",
                                        "        print(f\"\\nIzmantotie avoti: {used_sources}\")\n",
                                        "        print(\"-\" * 50)\n",
                                        "\n",
                                        "        chat_history.append({\"question\": user_question, \"answer\": response})\n",
                                        "        chat_history[:] = chat_history[-6:]\n",
                                        "\n",
                                        "        return {\n",
                                        "            \"question\": user_question,\n",
                                        "            \"answer\": response,\n",
                                        "            \"used_sources\": used_sources,\n",
                                        "        }\n",
                                        "    except Exception as e:\n",
                                        "        print(f\"Kļūda: {e}\")\n",
                                        "        return None\n",
                                        "\n",
                                        "\n",
                                        "def reset_chat_history():\n",
                                        "    chat_history.clear()\n",
                                        "    print(\"Čata vēsture notīrīta.\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 19,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "data": {
                                                            "text/html": [
                                                                      "<style>.kh-chat-output pre, .kh-chat-output .jp-OutputArea-output pre {white-space: pre-wrap !important; word-break: break-word !important;}</style>"
                                                            ],
                                                            "text/plain": [
                                                                      "<IPython.core.display.HTML object>"
                                                            ]
                                                  },
                                                  "metadata": {},
                                                  "output_type": "display_data"
                                        },
                                        {
                                                  "data": {
                                                            "application/vnd.jupyter.widget-view+json": {
                                                                      "model_id": "e38d2c3b2c1943eaabd9a2196b74b925",
                                                                      "version_major": 2,
                                                                      "version_minor": 0
                                                            },
                                                            "text/plain": [
                                                                      "HBox(children=(Text(value='', description='Jautājums:', layout=Layout(width='70%'), placeholder='Ieraksti jaut…"
                                                            ]
                                                  },
                                                  "metadata": {},
                                                  "output_type": "display_data"
                                        },
                                        {
                                                  "data": {
                                                            "application/vnd.jupyter.widget-view+json": {
                                                                      "model_id": "ed01d231108d4003a4cb39c47d6606c7",
                                                                      "version_major": 2,
                                                                      "version_minor": 0
                                                            },
                                                            "text/plain": [
                                                                      "Output(layout=Layout(border='1px solid #444', max_height='420px', overflow_x='auto', overflow_y='auto', paddin…"
                                                            ]
                                                  },
                                                  "metadata": {},
                                                  "output_type": "display_data"
                                        },
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Čata panelis gatavs. Raksti jautājumu laukā un spied Send.\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# Interaktīvs čata panelis vienā šūnā (bez jaunu šūnu veidošanas)\n",
                                        "try:\n",
                                        "    import ipywidgets as widgets\n",
                                        "    from IPython.display import display, HTML\n",
                                        "except Exception as e:\n",
                                        "    print(f\"UI nav pieejams: {e}\")\n",
                                        "    print(\"Instalē ipywidgets un palaid šūnu vēlreiz: pip install ipywidgets\")\n",
                                        "else:\n",
                                        "    question_box = widgets.Text(\n",
                                        "        placeholder=\"Ieraksti jautājumu un spied Send\",\n",
                                        "        description=\"Jautājums:\",\n",
                                        "        layout=widgets.Layout(width=\"70%\"),\n",
                                        "    )\n",
                                        "    send_btn = widgets.Button(description=\"Send\", button_style=\"primary\")\n",
                                        "    clear_btn = widgets.Button(description=\"Notīrīt vēsturi\")\n",
                                        "    output = widgets.Output(\n",
                                        "        layout=widgets.Layout(\n",
                                        "            border=\"1px solid #444\",\n",
                                        "            padding=\"8px\",\n",
                                        "            max_height=\"420px\",\n",
                                        "            overflow_y=\"auto\",\n",
                                        "            overflow_x=\"auto\",\n",
                                        "        )\n",
                                        "    )\n",
                                        "    output.add_class(\"kh-chat-output\")\n",
                                        "\n",
                                        "    def _run_question(_=None):\n",
                                        "        q = (question_box.value or \"\").strip()\n",
                                        "        if not q:\n",
                                        "            return\n",
                                        "        question_box.value = \"\"\n",
                                        "        with output:\n",
                                        "            ask_question(q)\n",
                                        "\n",
                                        "    def _clear_history(_=None):\n",
                                        "        with output:\n",
                                        "            reset_chat_history()\n",
                                        "\n",
                                        "    send_btn.on_click(_run_question)\n",
                                        "    clear_btn.on_click(_clear_history)\n",
                                        "    if hasattr(question_box, \"on_submit\"):\n",
                                        "        question_box.on_submit(_run_question)\n",
                                        "\n",
                                        "    display(HTML(\"<style>.kh-chat-output pre, .kh-chat-output .jp-OutputArea-output pre {white-space: pre-wrap !important; word-break: break-word !important;}</style>\"))\n",
                                        "    display(widgets.HBox([question_box, send_btn, clear_btn]))\n",
                                        "    display(output)\n",
                                        "    print(\"Čata panelis gatavs. Raksti jautājumu laukā un spied Send.\")\n"
                              ]
                    }
          ],
          "metadata": {
                    "colab": {
                              "authorship_tag": "ABX9TyMcgAgxinuQsleioyqU0BxC",
                              "provenance": null
                    },
                    "kernelspec": {
                              "display_name": "Python 3 (ipykernel)",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.12.12"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 0
}
